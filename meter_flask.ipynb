{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meter_flask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikhaup/flask-app/blob/main/meter_flask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_XWSUExWm3f",
        "outputId": "5ac7fe42-3cd5-4e0b-9577-31b2c3ee84cb"
      },
      "source": [
        "!pip install flask-ngrok\r\n",
        "!pip install flask==0.12.2  # Newer versions of flask don't work in Colab\r\n",
        "                            # See https://github.com/plotly/dash/issues/257"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting flask==0.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/32/e3597cb19ffffe724ad4bf0beca4153419918e7fa4ba6a34b04ee4da3371/Flask-0.12.2-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=2.0 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.4->flask==0.12.2) (1.1.1)\n",
            "Installing collected packages: flask\n",
            "  Found existing installation: Flask 1.1.2\n",
            "    Uninstalling Flask-1.1.2:\n",
            "      Successfully uninstalled Flask-1.1.2\n",
            "Successfully installed flask-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0D7aBEuVeWz",
        "outputId": "6a908a56-c268-46e3-9b2a-358272f93d8f"
      },
      "source": [
        "%%writefile /content/templates/home.html\r\n",
        "<!DOCTYPE html>\r\n",
        "<html>\r\n",
        "<head>\r\n",
        " <title>Meter Reading App</title>\r\n",
        "</head>\r\n",
        "<body>\r\n",
        " <h2>Upload your meter image</h2>\r\n",
        " <form method ='post' enctype=multipart/form-data>\r\n",
        "  <input type=\"file\" name=\"file\">\r\n",
        "  <input type=\"submit\" value=\"upload\">\r\n",
        "</body>\r\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/templates/home.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTYwxXdIWN3c",
        "outputId": "2cfb7216-3fd8-4d15-9e94-2cca2e35c1b6"
      },
      "source": [
        "%%writefile /content/templates/result.html\r\n",
        "<!DOCTYPE html>\r\n",
        "<html>\r\n",
        "<head>\r\n",
        "\t<title>Meter Reading App</title>\r\n",
        "</head>\r\n",
        "<body>\r\n",
        "  {% if filename %}\r\n",
        "\t<div>\r\n",
        "\t\t<img src=\"{{ url_for('display_image', filename=filename) }}\">\r\n",
        "\t</div>\r\n",
        "{% endif %}\r\n",
        "\t<h2>Prediction</h2>\r\n",
        "\t<p>Reading: {{ reading }}</p>\r\n",
        "</body>\r\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/templates/result.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r7Y2fziX7Y_",
        "outputId": "b065240d-ea99-438c-a64f-e86a9c5e63be"
      },
      "source": [
        "%%writefile app.py\r\n",
        "import torch\r\n",
        "from flask_ngrok import run_with_ngrok\r\n",
        "from flask import Flask\r\n",
        "from PIL import Image\r\n",
        "from flask import Flask, render_template, request, redirect, url_for,flash\r\n",
        "import string\r\n",
        "import os\r\n",
        "from CRNN.utils.utils import strLabelConverter, decode_prediction\r\n",
        "from inference import dataextraction, ImageProcessing\r\n",
        "\r\n",
        "alphabet = string.digits\r\n",
        "label_converter = strLabelConverter(alphabet)\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "UPLOAD_FOLDER = '/content/static/uploads/'\r\n",
        "\r\n",
        "\r\n",
        "app = Flask(__name__)\r\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\r\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\r\n",
        "app.secret_key = \"shikhaaa\"\r\n",
        "\r\n",
        "@app.route('/', methods=['GET', 'POST'])\r\n",
        "def hello_world():\r\n",
        "  if request.method == 'GET':\r\n",
        "    return render_template('home.html', value='hi')\r\n",
        "  if request.method == 'POST':\r\n",
        "    print(request.files)\r\n",
        "    file = request.files['file']\r\n",
        "    filename = file.filename\r\n",
        "    img = file.read()\r\n",
        "    \r\n",
        "    file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\r\n",
        "    \r\n",
        "    flash('Image successfully uploaded and displayed')\r\n",
        "\r\n",
        "    img = ImageProcessing(img)\r\n",
        "    pred_text = dataextraction(img, device, label_converter)\r\n",
        "    print(pred_text)\r\n",
        "    return render_template('result.html', reading=pred_text, filename=filename)\r\n",
        "\r\n",
        "@app.route('/display/<filename>')\r\n",
        "def display_image(filename):\r\n",
        "\t#print('display_image filename: ' + filename)\r\n",
        "\treturn redirect(url_for('static', filename='uploads/' + filename), code=301)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "  app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKLi07JOZQpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc2506e-84c7-4f03-a755-c30390b2a28c"
      },
      "source": [
        "!python app.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            " * Running on http://c8c7a3a38828.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "127.0.0.1 - - [30/Dec/2020 18:14:57] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Dec/2020 18:14:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "ImmutableMultiDict([('file', <FileStorage: '03048.png' ('image/png')>)])\n",
            "03\n",
            "127.0.0.1 - - [30/Dec/2020 18:15:20] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Dec/2020 18:15:20] \"\u001b[32mGET /display/03048.png HTTP/1.1\u001b[0m\" 301 -\n",
            "127.0.0.1 - - [30/Dec/2020 18:15:21] \"\u001b[37mGET /static/uploads/03048.png HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf9IoScBgS7j",
        "outputId": "52c031b1-1e00-45cd-f5cf-67d1d79a7a3c"
      },
      "source": [
        "%%writefile /content/CRNN/utils/utils.py\r\n",
        "import collections\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from numpy import mean\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class strLabelConverter(object):\r\n",
        "    \"\"\"Convert between str and label.\r\n",
        "        Insert `blank` to the alphabet for CTC.\r\n",
        "    Args:\r\n",
        "        alphabet (str): set of the possible characters.\r\n",
        "        ignore_case (bool, default=True): whether or not to ignore all of the case.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, alphabet: str, ignore_case: bool = True):\r\n",
        "        self._ignore_case = ignore_case\r\n",
        "        if self._ignore_case:\r\n",
        "            alphabet = alphabet.lower()\r\n",
        "        self.alphabet = alphabet + '-'  # for `-1` index\r\n",
        "\r\n",
        "        self.char2idx = {}\r\n",
        "        for i, char in enumerate(alphabet):\r\n",
        "            # NOTE: 0 is reserved for 'blank' required by wrap_ctc\r\n",
        "            self.char2idx[char] = i + 1\r\n",
        "        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\r\n",
        "\r\n",
        "    def encode(self, text):\r\n",
        "        \"\"\"Support batch or single str.\r\n",
        "        Args:\r\n",
        "            text (str or list of str): texts to convert.\r\n",
        "        Returns:\r\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\r\n",
        "            torch.IntTensor [n]: length of each text.\r\n",
        "        \"\"\"\r\n",
        "        # print(text)\r\n",
        "        if isinstance(text, str):\r\n",
        "            text = [\r\n",
        "                self.char2idx[char.lower() if self._ignore_case else char]\r\n",
        "                for char in text\r\n",
        "            ]\r\n",
        "            length = [len(text)]\r\n",
        "        elif isinstance(text, collections.Iterable):\r\n",
        "            length = [len(s) for s in text]\r\n",
        "            text = ''.join(text)\r\n",
        "            text, _ = self.encode(text)\r\n",
        "        return (torch.IntTensor(text), torch.IntTensor(length))\r\n",
        "\r\n",
        "    def decode(self, t, length, raw=False):\r\n",
        "        \"\"\"Decode encoded texts back into strs.\r\n",
        "        Args:\r\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\r\n",
        "            torch.IntTensor [n]: length of each text.\r\n",
        "        Raises:\r\n",
        "            AssertionError: when the texts and its length does not match.\r\n",
        "        Returns:\r\n",
        "            text (str or list of str): texts to convert.\r\n",
        "        \"\"\"\r\n",
        "        if length.numel() == 1:\r\n",
        "            length = length[0]\r\n",
        "            assert t.numel() == length, \"text with length: {} does not match declared length: {}\".format(t.numel(), length)\r\n",
        "            if raw:\r\n",
        "                return ''.join([self.alphabet[i - 1] for i in t])\r\n",
        "            else:\r\n",
        "                char_list = []\r\n",
        "                for i in range(length):\r\n",
        "                    if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):\r\n",
        "                        char_list.append(self.alphabet[t[i] - 1])\r\n",
        "                return ''.join(char_list)\r\n",
        "        else:\r\n",
        "            # batch mode\r\n",
        "            assert t.numel() == length.sum(), \"texts with length: {} does not match declared length: {}\".format(t.numel(), length.sum())\r\n",
        "            texts = []\r\n",
        "            index = 0\r\n",
        "            for i in range(length.numel()):\r\n",
        "                l = length[i]\r\n",
        "                texts.append(\r\n",
        "                    self.decode(\r\n",
        "                        t[index:index + l], torch.IntTensor([l]), raw=raw))\r\n",
        "                index += l\r\n",
        "        return texts\r\n",
        "\r\n",
        "\r\n",
        "def decode_prediction(logits: torch.Tensor, \r\n",
        "                      label_converter: strLabelConverter) -> str:\r\n",
        "    tokens = logits.softmax(2).argmax(2)\r\n",
        "    tokens = tokens.squeeze(1).numpy()\r\n",
        "    \r\n",
        "    # convert tor stings tokens\r\n",
        "    tokens = ''.join([label_converter.idx2char[token] \r\n",
        "                      if token != 0  else '-' \r\n",
        "                      for token in tokens])\r\n",
        "    tokens = tokens.split('-')\r\n",
        "    \r\n",
        "    # remove duplicates\r\n",
        "    text = [char \r\n",
        "            for batch_token in tokens \r\n",
        "            for idx, char in enumerate(batch_token)\r\n",
        "            if char != batch_token[idx-1] or len(batch_token) == 1]\r\n",
        "    text = ''.join(text)\r\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/CRNN/utils/utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlPXbiQmhUY-"
      },
      "source": [
        "!python /content/CRNN/utils/utils.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whQplbEg_Dw4",
        "outputId": "570d1c3e-152e-4f83-db6a-4000cc8dfc3d"
      },
      "source": [
        "%%writefile inference.py\r\n",
        "from __future__ import division\r\n",
        "import io\r\n",
        "\r\n",
        "import torch\r\n",
        "from pathlib import Path\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "import string\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from CRNN.utils.utils import strLabelConverter, decode_prediction\r\n",
        "\r\n",
        "def get_model():\r\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "  path = Path('/content/save.pt')\r\n",
        "  crnn = torch.load(path)\r\n",
        "  crnn.eval()\r\n",
        "  return crnn\r\n",
        "\r\n",
        "# This is the alternate function for get_tensor fucntion.... \r\n",
        "def ImageProcessing(image_bytes):\r\n",
        "  data_transform2 = transforms.Compose([transforms.ToTensor()])\r\n",
        "  img = Image.open(io.BytesIO(image_bytes))\r\n",
        "  # now we will return the tensor version of that image with resize .. as our input should be 300*75 resolution,\r\n",
        "  # if we want PIL format then we have to return without transformation and again have to do the resize in dataextraction \r\n",
        "  return data_transform2(img)\r\n",
        "  \r\n",
        "def dataextraction(img, device, label_converter):\r\n",
        "    # data_transform = transforms.Compose([transforms.ToTensor()])\r\n",
        "    # img = Image.open(io.BytesIO(img))\r\n",
        "    # img = data_transform(img)  #We don't have to do that now, as we already converted our image to tensor on Imageprocessing function.\r\n",
        "    crnn = get_model()\r\n",
        "    with torch.no_grad():\r\n",
        "        # crnn.eval()\r\n",
        "        img = img.unsqueeze(0)\r\n",
        "        logits = crnn(img.to(device))\r\n",
        "\r\n",
        "    pred_text = decode_prediction(logits.cpu(), label_converter)\r\n",
        "    return pred_text\r\n",
        "\r\n",
        "#crnn = get_model()\r\n",
        "#print(crnn.eval())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting inference.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ9nBfijgmd8"
      },
      "source": [
        "!python inference.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcvJjlO8wA7x"
      },
      "source": [
        "\r\n",
        "def get_model():\r\n",
        "\tcheckpoint_path = 'checkpoint_final.pth'\r\n",
        "\tmodel = models. densenet161(pretrained=True)\r\n",
        "\tmodel.classifier = nn.Linear(2208, 102)\r\n",
        "\tmodel.load_state_dict(torch.load(\r\n",
        "\t\tcheckpoint_path, map_location='cpu'), strict=False)\r\n",
        "\tmodel.eval()\r\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7Ap1T1zB_6"
      },
      "source": [
        "# This is the alternate function for get_tensor fucntion.... \r\n",
        "def ImageProcessing(image_bytes):\r\n",
        "  data_transform2 = transforms.Compose([transforms.Resize((300,75)),\r\n",
        "                                       transforms.ToTensor()])\r\n",
        "  img = Image.open(io.BytesIO(image_bytes))\r\n",
        "  # now we will return the tensor version of that image with resize .. as our input should be 300*75 resolution,\r\n",
        "  # if we want PIL format then we have to return without transformation and again have to do the resize in dataextraction \r\n",
        "  return data_transform2(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}